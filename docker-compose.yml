version: '3.8'

services:
  # PostgreSQL + pgvector
  postgres:
    image: pgvector/pgvector:pg15
    container_name: workflow-db
    environment:
      POSTGRES_DB: ${DB_NAME:-workflows_db}
      POSTGRES_USER: ${DB_USER:-workflow_user}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_HOST_AUTH_METHOD: scram-sha-256
    ports:
      - "${DB_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/app/db/schema.sql:/docker-entrypoint-initdb.d/01-schema.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER:-workflow_user}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # Backend FastAPI
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: workflow-backend
    environment:
      DATABASE_URL: postgresql://${DB_USER:-workflow_user}:${DB_PASSWORD}@postgres:5432/${DB_NAME:-workflows_db}
      PROJECT_NAME: ${PROJECT_NAME:-Workflow Manager}
      DEBUG: ${DEBUG:-true}
      API_V1_PREFIX: /api/v1
      BACKEND_CORS_ORIGINS: ${FRONTEND_URL:-http://localhost:3000},http://localhost:5173

      # LLM Config
      DEFAULT_LLM_PROVIDER: ${DEFAULT_LLM_PROVIDER:-ollama}
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL:-http://ollama:11434}
      OLLAMA_MODEL: ${OLLAMA_MODEL:-llama3.2:3b}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      OPENAI_MODEL: ${OPENAI_MODEL:-gpt-4o-mini}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
      ANTHROPIC_MODEL: ${ANTHROPIC_MODEL:-claude-sonnet-4-20250514}

      # RAG Config
      EMBEDDING_MODEL_NAME: ${EMBEDDING_MODEL_NAME:-sentence-transformers/all-MiniLM-L6-v2}
      CHUNK_SIZE: ${CHUNK_SIZE:-1000}
      CHUNK_OVERLAP: ${CHUNK_OVERLAP:-200}
      SECRET_KEY: ${SECRET_KEY:-change-me-in-production}
    ports:
      - "${BACKEND_PORT:-8000}:8000"
    volumes:
      - ./backend/app:/app/app  # HOT-RELOAD: Monte le code source
      - model_cache:/root/.cache
    command: ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]  # HOT-RELOAD: Active le reload auto
    depends_on:
      postgres:
        condition: service_healthy
      ollama:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # Frontend Vue 3
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.dev  # HOT-RELOAD: Utilise Vite dev server
    container_name: workflow-frontend
    ports:
      - "${FRONTEND_PORT:-5173}:5173"  # HOT-RELOAD: Port Vite au lieu de Nginx
    volumes:
      - ./frontend:/app  # HOT-RELOAD: Monte le code source
      - /app/node_modules  # Exclut node_modules (reste dans le conteneur)
    environment:
      - VITE_API_BASE_URL=${BACKEND_URL:-http://localhost:8001}
    depends_on:
      - backend
    restart: unless-stopped

  # Ollama (LLM local)
  ollama:
    image: ollama/ollama:latest
    container_name: workflow-ollama
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    restart: unless-stopped

volumes:
  postgres_data:
  ollama_data:
  model_cache:

networks:
  default:
    name: workflow-network
